{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
        "from scipy.stats import skew\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "ihziY8Vllf1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Tentukan Path untuk Input dan Output\n",
        "input_path = \"/content/drive/MyDrive//Result_Preprocessed(fix)\"\n",
        "output_csv = \"/content/drive/MyDrive/Ekstraksi_GLCM&LBP_(fix).csv\"\n",
        "\n",
        "# 3. Folder kategori\n",
        "classes = ['Berkualitas', 'Kurang Berkualitas', 'Tidak Berkualitas']\n",
        "\n",
        "# 4. Fungsi untuk mendapatkan usia simpan berdasarkan nama file\n",
        "def get_storage_age(filename):\n",
        "    if filename.startswith('0_'):\n",
        "        return '0 minggu'\n",
        "    elif filename.startswith('1_'):\n",
        "        return '1 minggu'\n",
        "    elif filename.startswith('2_'):\n",
        "        return '2 minggu'\n",
        "    elif filename.startswith('3_'):\n",
        "        return '3 minggu'\n",
        "    elif filename.startswith('4_'):\n",
        "        return '4 minggu'\n",
        "    elif filename.startswith('5_'):\n",
        "        return '5 minggu'\n",
        "    else:\n",
        "        return 'Tidak diketahui'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VghclMNGljeU",
        "outputId": "4781ce30-e85c-4530-870f-b03e54bf491b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk Gamma Correction (untuk meningkatkan kontras gambar)\n",
        "def gamma_correction(image, gamma=1.5):\n",
        "    # Menggunakan gamma correction untuk meningkatkan kontras gambar\n",
        "    gamma_corrected = np.array(255 * (image / 255) ** gamma, dtype='uint8')\n",
        "    return gamma_corrected\n",
        "\n",
        "# Fungsi untuk normalisasi gambar (Quantization)\n",
        "def normalize_image(image, levels=8):\n",
        "    image = np.float32(image)\n",
        "    normalized_image = cv2.normalize(image, None, 0, levels - 1, cv2.NORM_MINMAX)\n",
        "    return np.uint8(normalized_image)\n",
        "\n",
        "# Fungsi untuk Histogram Equalization (CLAHE)\n",
        "def apply_clahe(image):\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    equalized_image = clahe.apply(gray)\n",
        "    return equalized_image\n",
        "\n",
        "# Fungsi untuk Z-Score Normalization pada fitur\n",
        "def z_score_normalization(features):\n",
        "    return (features - np.mean(features)) / np.std(features)"
      ],
      "metadata": {
        "id": "2DhWW3MF9ezf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Ekstraksi Fitur GLCM ======\n",
        "def extract_glcm_features(image, levels=8):\n",
        "    # Terapkan CLAHE dan Gamma correction untuk memperbaiki distribusi\n",
        "    equalized_image = apply_clahe(image)\n",
        "    corrected_image = gamma_correction(equalized_image)\n",
        "    quantized_image = normalize_image(corrected_image, levels=levels)\n",
        "\n",
        "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "    distances = [1]\n",
        "\n",
        "    glcm = graycomatrix(quantized_image, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
        "    glcm = np.squeeze(glcm)\n",
        "\n",
        "    contrast, correlation, energy, homogeneity = 0, 0, 0, 0\n",
        "    for i in range(len(angles)):\n",
        "        contrast += np.sum((np.arange(levels)[:, None] - np.arange(levels))**2 * glcm[:,:,i])\n",
        "        mean_x = np.mean(np.arange(levels)[:, None] * glcm[:,:,i], axis=0)\n",
        "        mean_y = np.mean(np.arange(levels) * glcm[:,:,i], axis=1)\n",
        "        correlation += np.sum((np.arange(levels)[:, None] - mean_x) * (np.arange(levels) - mean_y) * glcm[:,:,i])\n",
        "        energy += np.sum(glcm[:,:,i]**2)\n",
        "        homogeneity += np.sum(glcm[:,:,i] / (1 + np.abs(np.arange(levels)[:, None] - np.arange(levels))))\n",
        "\n",
        "    contrast /= len(angles)\n",
        "    correlation /= len(angles)\n",
        "    energy /= len(angles)\n",
        "    homogeneity /= len(angles)\n",
        "\n",
        "    entropy = -np.mean([np.sum(glcm[:,:,i] * np.log2(glcm[:,:,i] + 1e-12)) for i in range(len(angles))])\n",
        "\n",
        "    variance_glcm = np.mean([np.sum((np.arange(levels)[:, None] - np.mean(quantized_image))**2 * glcm[:,:,i]) for i in range(len(angles))])\n",
        "    std_dev_glcm = np.sqrt(variance_glcm)\n",
        "\n",
        "    skewness_glcm = skew(quantized_image.flatten())\n",
        "\n",
        "    mean_glcm_features = np.mean([contrast, correlation, energy, homogeneity, entropy, variance_glcm, std_dev_glcm, skewness_glcm])\n",
        "\n",
        "    return contrast, correlation, energy, homogeneity, entropy, variance_glcm, std_dev_glcm, skewness_glcm, mean_glcm_features\n"
      ],
      "metadata": {
        "id": "ehIZA4qg9hGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Ekstraksi Fitur LBP ======\n",
        "def extract_lbp_features(image, P=8, R=1, levels=8):\n",
        "    equalized_image = apply_clahe(image)\n",
        "    corrected_image = gamma_correction(equalized_image)\n",
        "    quantized_image = normalize_image(corrected_image, levels=levels)\n",
        "\n",
        "    lbp = local_binary_pattern(quantized_image, P, R, method='uniform')\n",
        "\n",
        "    lbp_histogram, _ = np.histogram(lbp.ravel(), bins=np.arange(0, P + 3), range=(0, P + 2))\n",
        "    lbp_histogram = lbp_histogram.astype('float')\n",
        "    lbp_histogram /= (lbp_histogram.sum() + 1e-6)\n",
        "\n",
        "    lbp_energy = np.sum(lbp_histogram ** 2)\n",
        "    lbp_entropy = -np.sum(lbp_histogram * np.log2(lbp_histogram + (lbp_histogram == 0)))\n",
        "    lbp_contrast = np.sum((np.arange(0, P + 2) ** 2) * lbp_histogram)\n",
        "    lbp_homogeneity = np.sum(lbp_histogram / (1 + np.abs(np.arange(0, P + 2)[:, None] - np.arange(0, P + 2))))\n",
        "    lbp_variance = np.var(lbp_histogram)\n",
        "    lbp_std_dev = np.std(lbp_histogram)\n",
        "\n",
        "    lbp_contrast_norm = lbp_contrast / ((P + 2 - 1) ** 2) if lbp_contrast > 0 else 0\n",
        "    lbp_variance_norm = lbp_variance / ((P + 2 - 1) / 2) ** 2 if lbp_variance > 0 else 0\n",
        "    lbp_std_dev_norm = lbp_std_dev / ((P + 2 - 1) / 2) if lbp_std_dev > 0 else 0\n",
        "\n",
        "    lbp_entropy_norm = lbp_entropy / np.log2(P + 2) if lbp_entropy > 0 else 0\n",
        "    lbp_homogeneity_norm = lbp_homogeneity / 1.0 if lbp_homogeneity > 0 else 0\n",
        "\n",
        "    skewness_lbp = skew(lbp_histogram)\n",
        "\n",
        "    mean_lbp_features = np.mean([lbp_energy, lbp_entropy_norm, lbp_contrast_norm, lbp_homogeneity_norm, lbp_variance_norm, lbp_std_dev_norm, skewness_lbp])\n",
        "\n",
        "    return lbp_energy, lbp_entropy_norm, lbp_contrast_norm, lbp_homogeneity_norm, lbp_variance_norm, lbp_std_dev_norm, skewness_lbp, mean_lbp_features\n"
      ],
      "metadata": {
        "id": "k2gW1gdq9iy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Memproses Semua Gambar dan Menyimpan Fitur ke CSV ======\n",
        "def process_and_extract_features(input_path, output_csv):\n",
        "    columns = ['filename', 'contrast_glcm', 'correlation_glcm', 'energy_glcm', 'homogeneity_glcm', 'entropy_glcm', 'variance_glcm', 'std_dev_glcm', 'skewness_glcm', 'mean_glcm',\n",
        "               'energy_lbp', 'entropy_lbp', 'contrast_lbp', 'homogeneity_lbp', 'variance_lbp', 'std_dev_lbp', 'skewness_lbp', 'mean_lbp', 'kelas_kualitas', 'usia_simpan']\n",
        "\n",
        "    features_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "    classes = ['Berkualitas', 'Kurang Berkualitas', 'Tidak Berkualitas']\n",
        "\n",
        "    for kls in classes:\n",
        "        input_dir = os.path.join(input_path, kls)\n",
        "\n",
        "        for filename in tqdm(os.listdir(input_dir), desc=f\"Proses {kls}\"):\n",
        "            if filename.lower().endswith(\".jpg\"):\n",
        "                path_img = os.path.join(input_dir, filename)\n",
        "                img = cv2.imread(path_img)\n",
        "\n",
        "                # Cek apakah gambar berhasil dibaca\n",
        "                if img is None:\n",
        "                    print(f\"Gambar {filename} tidak dapat dibaca. Melewatkan gambar.\")\n",
        "                    continue  # Melewati gambar yang tidak bisa dibaca\n",
        "\n",
        "                # Ekstraksi fitur GLCM (sudah dinormalisasi)\n",
        "                glcm_features = extract_glcm_features(img)\n",
        "\n",
        "                # Ekstraksi fitur LBP (sudah dinormalisasi)\n",
        "                lbp_features = extract_lbp_features(img)\n",
        "\n",
        "                # Menyimpan fitur yang diekstraksi ke dataframe\n",
        "                base_name = os.path.splitext(filename)[0]\n",
        "                analysis_row = pd.DataFrame([{\n",
        "                    'filename': filename,\n",
        "                    'contrast_glcm': glcm_features[0],\n",
        "                    'correlation_glcm': glcm_features[1],\n",
        "                    'energy_glcm': glcm_features[2],\n",
        "                    'homogeneity_glcm': glcm_features[3],\n",
        "                    'entropy_glcm': glcm_features[4],\n",
        "                    'variance_glcm': glcm_features[5],\n",
        "                    'std_dev_glcm': glcm_features[6],\n",
        "                    'skewness_glcm': glcm_features[7],\n",
        "                    'mean_glcm': glcm_features[8],\n",
        "                    'energy_lbp': lbp_features[0],\n",
        "                    'entropy_lbp': lbp_features[1],\n",
        "                    'contrast_lbp': lbp_features[2],\n",
        "                    'homogeneity_lbp': lbp_features[3],\n",
        "                    'variance_lbp': lbp_features[4],\n",
        "                    'std_dev_lbp': lbp_features[5],\n",
        "                    'skewness_lbp': lbp_features[6],\n",
        "                    'mean_lbp': lbp_features[7],\n",
        "                    'kelas_kualitas': kls,\n",
        "                    'usia_simpan': get_storage_age(filename)\n",
        "                }])\n",
        "\n",
        "                # Menggunakan concat untuk menambahkan baris\n",
        "                features_df = pd.concat([features_df, analysis_row], ignore_index=True)\n",
        "\n",
        "    # Menyimpan hasil ekstraksi fitur ke CSV\n",
        "    features_df.to_csv(output_csv, index=False)"
      ],
      "metadata": {
        "id": "OBmknJRU9kwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Panggil proses untuk ekstraksi fitur dan simpan ke CSV\n",
        "process_and_extract_features(input_path, output_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U2Rr-Pe9l6k",
        "outputId": "3c5cb61d-00c5-4394-c74c-afe5d99e514e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Proses Berkualitas:   0%|          | 0/810 [00:00<?, ?it/s]/tmp/ipython-input-1280554066.py:55: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  features_df = pd.concat([features_df, analysis_row], ignore_index=True)\n",
            "Proses Berkualitas: 100%|██████████| 810/810 [00:54<00:00, 14.78it/s]\n",
            "Proses Kurang Berkualitas: 100%|██████████| 810/810 [00:41<00:00, 19.30it/s]\n",
            "Proses Tidak Berkualitas: 100%|██████████| 810/810 [01:14<00:00, 10.82it/s]\n"
          ]
        }
      ]
    }
  ]
}